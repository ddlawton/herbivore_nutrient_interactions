{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental variable correlations"
   ],
   "id": "2a6cec55-1aba-4f5d-99e2-30d528153638"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script extracts nitrogen, phosphorus, woody vegetation pixel coverage, and mean annual precipitation from google earth engine for correlation\n",
    "\n",
    "The purpose is to show how the locust outbreak model disentangled the positive correlation between nitrogen and these variables\n",
    "\n",
    "read the manuscript for further discussion\n",
    "\n",
    "# Import libraries and initialize google earth engine"
   ],
   "id": "b4b952d5-f86b-46c1-9b31-f8f2e9a81f8c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import os \n",
    "import time\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize()\n"
   ],
   "id": "fa0b44ae-a001-41b2-bfb0-fb4051d24448"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set relative work directory"
   ],
   "id": "87f45436-28d1-4eae-90a4-4f39b42fbd92"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "'/home/datascience/herbivore_nutrient_interactions'"
      ]
     }
    }
   ],
   "source": [
    "os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "os.getcwd()"
   ],
   "id": "526f163d-a835-487f-b6e7-fc8ba9a75d6a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Australia shape"
   ],
   "id": "3a58d36b-7ccd-47c1-b12e-cdc5eadb2f42"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the countries feature collection\n",
    "countries = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")\n",
    "\n",
    "# Filter the feature collection to get the boundary of Australia\n",
    "australia = countries.filter(ee.Filter.eq('country_na', 'Australia'))\n",
    "\n"
   ],
   "id": "5f3c01ac-f301-405e-ba0c-7b87cc1fa8c5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in rasters"
   ],
   "id": "d52e0539-250d-4095-96f7-9dc08c11f1b6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the two rasters\n",
    "raster1 = ee.ImageCollection('CSIRO/SLGA') \\\n",
    "    .filter(ee.Filter.eq('attribute_code', 'NTO')) \\\n",
    "    .select(['NTO_000_005_EV', 'NTO_005_015_EV']).mean()\n",
    "\n",
    "raster2 = ee.ImageCollection(\"NASA/MEASURES/GFCC/TC/v3\") \\\n",
    "    .select(\"tree_canopy_cover\") \\\n",
    "    .filter(ee.Filter.calendarRange(2000, 2017, 'year')).mean()\n",
    "\n",
    "raster3 = ee.Image(\"WORLDCLIM/V1/BIO\").select('bio12')\n",
    "\n",
    "raster4 = ee.ImageCollection('CSIRO/SLGA') \\\n",
    "    .filter(ee.Filter.eq('attribute_code', 'PTO')) \\\n",
    "    .select(['PTO_000_005_EV', 'PTO_005_015_EV']).mean()\n",
    "\n",
    "# Combine the temperature bands from each image into a single image\n",
    "temp_bands = raster1.addBands(raster2).addBands(raster3).addBands(raster4)\n",
    "\n"
   ],
   "id": "6e574186-71f8-474b-ad3b-561701b536b3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample the australia shapefile"
   ],
   "id": "8b77090a-14ab-4a79-b2fc-b346f4754ac2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate random points\n",
    "sample = ee.FeatureCollection.randomPoints(\n",
    "        region=australia, points=100000, seed=420, maxError=1\n",
    ")\n",
    "\n",
    "# Sample the the bands using the sample point feature collection.\n",
    "imgSamp = temp_bands.sampleRegions(\n",
    "  collection = sample,\n",
    "  scale = 30\n",
    ")\n"
   ],
   "id": "90f8c383-453f-41ee-844e-afaf21a984d8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For loop to extract data from google earth engine"
   ],
   "id": "53fed578-8fa3-4986-ac09-2dfb70d01d51"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed batch 1 to 500\n",
      "Processed batch 501 to 1000\n",
      "Processed batch 1001 to 1500\n",
      "Processed batch 1501 to 2000\n",
      "Processed batch 2001 to 2500\n",
      "Processed batch 2501 to 3000\n",
      "Processed batch 3001 to 3500\n",
      "Processed batch 3501 to 4000\n",
      "Processed batch 4001 to 4500\n",
      "Processed batch 4501 to 5000\n",
      "Processed batch 5001 to 5500\n",
      "Processed batch 5501 to 6000\n",
      "Processed batch 6001 to 6500\n",
      "Processed batch 6501 to 7000\n",
      "Processed batch 7001 to 7500\n",
      "Processed batch 7501 to 8000\n",
      "Processed batch 8001 to 8500\n",
      "Processed batch 8501 to 9000\n",
      "Processed batch 9001 to 9500\n",
      "Processed batch 9501 to 10000\n",
      "Processed batch 10001 to 10500\n",
      "Processed batch 10501 to 11000\n",
      "Processed batch 11001 to 11500\n",
      "Processed batch 11501 to 12000\n",
      "Processed batch 12001 to 12500\n",
      "Processed batch 12501 to 13000\n",
      "Processed batch 13001 to 13500\n",
      "Processed batch 13501 to 14000\n",
      "Processed batch 14001 to 14500\n",
      "Processed batch 14501 to 15000\n",
      "Processed batch 15001 to 15500\n",
      "Processed batch 15501 to 16000\n",
      "Processed batch 16001 to 16500\n",
      "Processed batch 16501 to 17000\n",
      "Processed batch 17001 to 17500\n",
      "Processed batch 17501 to 18000\n",
      "Processed batch 18001 to 18500\n",
      "Processed batch 18501 to 19000\n",
      "Processed batch 19001 to 19500\n",
      "Processed batch 19501 to 20000\n",
      "Processed batch 20001 to 20500\n",
      "Processed batch 20501 to 21000\n",
      "Processed batch 21001 to 21500\n",
      "Processed batch 21501 to 22000\n",
      "Processed batch 22001 to 22500\n",
      "Processed batch 22501 to 23000\n",
      "Processed batch 23001 to 23500\n",
      "Processed batch 23501 to 24000\n",
      "Processed batch 24001 to 24500\n",
      "Processed batch 24501 to 25000\n",
      "Processed batch 25001 to 25500\n",
      "Processed batch 25501 to 26000\n",
      "Processed batch 26001 to 26500\n",
      "Processed batch 26501 to 27000\n",
      "Processed batch 27001 to 27500\n",
      "Processed batch 27501 to 28000\n",
      "Processed batch 28001 to 28500\n",
      "Processed batch 28501 to 29000\n",
      "Processed batch 29001 to 29500\n",
      "Processed batch 29501 to 30000\n",
      "Processed batch 30001 to 30500\n",
      "Processed batch 30501 to 31000\n",
      "Processed batch 31001 to 31500\n",
      "Processed batch 31501 to 32000\n",
      "Processed batch 32001 to 32500\n",
      "Processed batch 32501 to 33000\n",
      "Processed batch 33001 to 33500\n",
      "Processed batch 33501 to 34000\n",
      "Processed batch 34001 to 34500\n",
      "Processed batch 34501 to 35000\n",
      "Processed batch 35001 to 35500\n",
      "Processed batch 35501 to 36000\n",
      "Processed batch 36001 to 36500\n",
      "Processed batch 36501 to 37000\n",
      "Processed batch 37001 to 37500\n",
      "Processed batch 37501 to 38000\n",
      "Processed batch 38001 to 38500\n",
      "Processed batch 38501 to 39000\n",
      "Processed batch 39001 to 39500\n",
      "Processed batch 39501 to 40000\n",
      "Processed batch 40001 to 40500\n",
      "Processed batch 40501 to 41000\n",
      "Processed batch 41001 to 41500\n",
      "Processed batch 41501 to 42000\n",
      "Processed batch 42001 to 42500\n",
      "Processed batch 42501 to 43000\n",
      "Processed batch 43001 to 43500\n",
      "Processed batch 43501 to 44000\n",
      "Processed batch 44001 to 44500\n",
      "Processed batch 44501 to 45000\n",
      "Processed batch 45001 to 45500\n",
      "Processed batch 45501 to 46000\n",
      "Processed batch 46001 to 46500\n",
      "Processed batch 46501 to 47000\n",
      "Processed batch 47001 to 47500\n",
      "Processed batch 47501 to 48000\n",
      "Processed batch 48001 to 48500\n",
      "Processed batch 48501 to 49000\n",
      "Processed batch 49001 to 49500\n",
      "Processed batch 49501 to 50000\n",
      "Processed batch 50001 to 50500\n",
      "Processed batch 50501 to 51000\n",
      "Processed batch 51001 to 51500\n",
      "Processed batch 51501 to 52000\n",
      "Processed batch 52001 to 52500\n",
      "Processed batch 52501 to 53000\n",
      "Processed batch 53001 to 53500\n",
      "Processed batch 53501 to 54000\n",
      "Processed batch 54001 to 54500\n",
      "Processed batch 54501 to 55000\n",
      "Processed batch 55001 to 55500\n",
      "Processed batch 55501 to 56000\n",
      "Processed batch 56001 to 56500\n",
      "Processed batch 56501 to 57000\n",
      "Processed batch 57001 to 57500\n",
      "Processed batch 57501 to 58000\n",
      "Processed batch 58001 to 58500\n",
      "Processed batch 58501 to 59000\n",
      "Processed batch 59001 to 59500\n",
      "Processed batch 59501 to 60000\n",
      "Processed batch 60001 to 60500\n",
      "Processed batch 60501 to 61000\n",
      "Processed batch 61001 to 61500\n",
      "Processed batch 61501 to 62000\n",
      "Processed batch 62001 to 62500\n",
      "Processed batch 62501 to 63000\n",
      "Processed batch 63001 to 63500\n",
      "Processed batch 63501 to 64000\n",
      "Processed batch 64001 to 64500\n",
      "Processed batch 64501 to 65000\n",
      "Processed batch 65001 to 65500\n",
      "Processed batch 65501 to 66000\n",
      "Processed batch 66001 to 66500\n",
      "Processed batch 66501 to 67000\n",
      "Processed batch 67001 to 67500\n",
      "Processed batch 67501 to 68000\n",
      "Processed batch 68001 to 68500\n",
      "Processed batch 68501 to 69000\n",
      "Processed batch 69001 to 69500\n",
      "Processed batch 69501 to 70000\n",
      "Processed batch 70001 to 70500\n",
      "Processed batch 70501 to 71000\n",
      "Processed batch 71001 to 71500\n",
      "Processed batch 71501 to 72000\n",
      "Processed batch 72001 to 72500\n",
      "Processed batch 72501 to 73000\n",
      "Processed batch 73001 to 73500\n",
      "Processed batch 73501 to 74000\n",
      "Processed batch 74001 to 74500\n",
      "Processed batch 74501 to 75000\n",
      "Processed batch 75001 to 75500\n",
      "Processed batch 75501 to 76000\n",
      "Processed batch 76001 to 76500\n",
      "Processed batch 76501 to 77000\n",
      "Processed batch 77001 to 77500\n",
      "Processed batch 77501 to 78000\n",
      "Processed batch 78001 to 78500\n",
      "Processed batch 78501 to 79000\n",
      "Processed batch 79001 to 79500\n",
      "Processed batch 79501 to 80000\n",
      "Processed batch 80001 to 80500\n",
      "Processed batch 80501 to 81000\n",
      "Processed batch 81001 to 81500\n",
      "Processed batch 81501 to 82000\n",
      "Processed batch 82001 to 82500\n",
      "Processed batch 82501 to 83000\n",
      "Processed batch 83001 to 83500\n",
      "Processed batch 83501 to 84000\n",
      "Processed batch 84001 to 84500\n",
      "Processed batch 84501 to 85000\n",
      "Processed batch 85001 to 85500\n",
      "Processed batch 85501 to 86000\n",
      "Processed batch 86001 to 86500\n",
      "Processed batch 86501 to 87000\n",
      "Processed batch 87001 to 87500\n",
      "Processed batch 87501 to 88000\n",
      "Processed batch 88001 to 88500\n",
      "Processed batch 88501 to 89000\n",
      "Processed batch 89001 to 89500\n",
      "Processed batch 89501 to 90000\n",
      "Processed batch 90001 to 90500\n",
      "Processed batch 90501 to 91000\n",
      "Processed batch 91001 to 91500\n",
      "Processed batch 91501 to 92000\n",
      "Processed batch 92001 to 92500\n",
      "Processed batch 92501 to 93000\n",
      "Processed batch 93001 to 93500\n",
      "Processed batch 93501 to 94000\n",
      "Processed batch 94001 to 94500\n",
      "Processed batch 94501 to 95000\n",
      "Processed batch 95001 to 95500\n",
      "Processed batch 95501 to 96000\n",
      "Processed batch 96001 to 96500\n",
      "Processed batch 96501 to 97000\n",
      "Processed batch 97001 to 97500\n",
      "Processed batch 97501 to 98000\n",
      "Processed batch 98001 to 98500\n",
      "Processed batch 98501 to 99000\n",
      "Processed batch 99001 to 99500\n",
      "Processed batch 99501 to 100000\n",
      "   NTO_000_005_EV  NTO_005_015_EV  PTO_000_005_EV  PTO_005_015_EV  bio12  \\\n",
      "0        0.036264        0.032103        0.017605        0.016432    223   \n",
      "1        0.031465        0.029525        0.018839        0.018417    163   \n",
      "2        0.060444        0.055346        0.022199        0.021432   1050   \n",
      "3        0.147743        0.118303        0.029048        0.026754    850   \n",
      "4        0.048120        0.042801        0.024990        0.024281    289   \n",
      "\n",
      "   tree_canopy_cover  \n",
      "0               0.00  \n",
      "1               0.00  \n",
      "2              11.00  \n",
      "3               5.00  \n",
      "4               2.75  "
     ]
    }
   ],
   "source": [
    "\n",
    "# Set batch size\n",
    "batch_size = 500\n",
    "total_points = 100000\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Process in batches of 500\n",
    "for start in range(0, total_points, batch_size):\n",
    "    # Define the end of the batch\n",
    "    end = min(start + batch_size, total_points)\n",
    "\n",
    "    # Get the batch of points\n",
    "    batch_sample = sample.toList(batch_size, start)\n",
    "    batch_sample_fc = ee.FeatureCollection(batch_sample)\n",
    "\n",
    "    # Sample the raster data\n",
    "    img_samp_batch = temp_bands.sampleRegions(\n",
    "        collection=batch_sample_fc,\n",
    "        scale=30\n",
    "    )\n",
    "\n",
    "    # Get the result as a list of dictionaries\n",
    "    try:\n",
    "        sample_dict = img_samp_batch.getInfo()['features']\n",
    "        rows = [feature['properties'] for feature in sample_dict]\n",
    "        df_batch = pd.DataFrame(rows)\n",
    "\n",
    "        # Append the batch to the main DataFrame\n",
    "        df = pd.concat([df, df_batch], ignore_index=True)\n",
    "\n",
    "        print(f\"Processed batch {start + 1} to {end}\")\n",
    "\n",
    "        # Add a delay to avoid overwhelming the API\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {start + 1} to {end}: {e}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ],
   "id": "075e31d3-8462-4648-8b70-41e6c5756786"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/processed/spatial_modeling/environmental_correlation_data.csv', index=False)\n"
   ],
   "id": "0572afc1-3e41-4dd5-87d8-bf9bdc360b75"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
