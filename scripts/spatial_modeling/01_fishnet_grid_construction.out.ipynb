{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point to grid conversion"
   ],
   "id": "ed911d44-2458-4f44-9975-846f5c533d91"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes the georeferenced points and related them to a fishnet grid of 1km x 1km scale.\n",
    "\n",
    "This will be for both for Australian Plague Locust and Desert Locust"
   ],
   "id": "f0842cfa-9614-4820-91ca-5967aa8de101"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os"
   ],
   "id": "8cb97841-63d4-4070-a986-089de1d711e8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "'/home/datascience/herbivore_nutrient_interactions'"
      ]
     }
    }
   ],
   "source": [
    "os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "os.getcwd()"
   ],
   "id": "1184a69a-588f-4522-bd5a-04540769e463"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the point dataset and creates a sparse fishnet grid that overlaps with all points. \n",
    "# there is a user species cell size and few other handy parameters\n",
    "# it defaults to parallel processing but can be turned off\n",
    "\n",
    "# it creates a bounding box, creates a coarse grid, filters out unused grids and then within each coarse grid, it creates the fine scale grid\n",
    "# at the speicifed cell size and then removes unused grids.\n",
    "\n",
    "with open('scripts/functions/fishnet_grid_function.py') as f:\n",
    "    code = f.read()\n",
    "\n",
    "# Execute the code\n",
    "exec(code)\n"
   ],
   "id": "20638780-1e5a-4d63-b733-5b41a2670c7b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Australian plague locust data\n",
    "\n",
    "This dataset is comprised of several species but the records are biased towards the more economically important species (e.g. australian plauge locust)\n",
    "\n",
    "## Species identifier\n",
    "\n",
    "The `Species` column is the identifier per species\n",
    "\n",
    "-   10 = no locust/grasshopper found\n",
    "-   11 = Australian plague locust (*Chortocietes terminifera*)\n",
    "-   12 = Spur-throated locust (*Austracris guttulosa*)\n",
    "-   15 = Small plague locust (*Austroicetes cruciata*)\n",
    "-   19 = Eastern plague grasshopper (*Oedaleus australis*)\n",
    "\n",
    "### Species data management\n",
    "\n",
    "For each species, we need to combined the species specific ID with the `10` observations (nil-observations) and observations in the other species categories that are nil. This will provide us with all the records that a specific grasshopper species was present and combine it with all the nil observation possible."
   ],
   "id": "8fc96b44-606b-41f5-9a89-e7d7806adb4c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "<p>303834 rows × 11 columns</p>\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "CT = pd.read_csv('data/raw/survey_data/CT.csv')\n",
    "OA = pd.read_csv('data/raw/survey_data/OA.csv')\n",
    "AG = pd.read_csv('data/raw/survey_data/AG.csv')\n",
    "AC = pd.read_csv('data/raw/survey_data/AC.csv')\n",
    "\n",
    "# Add a species column to each dataframe\n",
    "CT['species'] = 'CT'\n",
    "OA['species'] = 'OA'\n",
    "AG['species'] = 'AG'\n",
    "AC['species'] = 'AC'\n",
    "\n",
    "# Combine all the dataframes\n",
    "combined_df = pd.concat([CT, OA, AG, AC], ignore_index=True).drop(columns=['Longitude2', 'Latitude2','Unnamed: 0'])\n",
    "combined_df"
   ],
   "id": "19398ba1-1ad5-44d4-a42c-c26ee37c0a52"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fishnet grid construction\n",
    "\n",
    "I first create the sparse fishnet grid (roughly 1km x 1km) and then aggregate the species data to the polygons. This is done BY species and not between."
   ],
   "id": "388f01d6-e1dd-4b17-8d51-6c1e367650f4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing Polygons: 100%|██████████| 1315/1315 [00:17<00:00, 73.10it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "aplc_survey_dataframe = create_grids_parallel(\n",
    "        combined_df,\n",
    "        longitude_column='Longitude',\n",
    "        latitude_column='Latitude',\n",
    "        csv_crs='EPSG:4326',\n",
    "        grid_crs='EPSG:4326',\n",
    "        transformation_crs='EPSG:4326',\n",
    "        final_cell_size=0.01,\n",
    "        coarse_cell_size=None,\n",
    "        parallel=True\n",
    "    )\n",
    "\n"
   ],
   "id": "b518e127-c4da-4ed5-a189-161cb686a630"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "<p>67144 rows × 2 columns</p>\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "# Add an index to the polygons\n",
    "## this will allow us to join tables together (and make GEE easier)\n",
    "\n",
    "aplc_survey_dataframe = gpd.GeoDataFrame(aplc_survey_dataframe)\n",
    "aplc_survey_dataframe['polygon_id'] = aplc_survey_dataframe.index\n",
    "aplc_survey_dataframe.set_crs(epsg=4326, inplace=True)"
   ],
   "id": "cd8ea9d3-c931-4001-81c5-983391ccfa35"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets summarize the APL point data to the polygon grid data"
   ],
   "id": "b00cb0d8-975b-4481-b829-08246f656ab0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "<p>303834 rows × 11 columns</p>\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "combined_df"
   ],
   "id": "9714e545-1812-4775-aab4-ed0f7c5a454c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['Longitude', 'Latitude', 'Date','Species','Data.Quality','Nymph.Density','Adult.Density']\n",
    "APL_dat = combined_df[columns_to_keep]\n"
   ],
   "id": "674d1a74-aa45-4e26-a3b1-335111a9e054"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "<p>303834 rows × 8 columns</p>\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "# Convert DataFrame to GeoDataFrame\n",
    "\n",
    "gdf_points = gpd.GeoDataFrame(\n",
    "    APL_dat,\n",
    "    geometry=gpd.points_from_xy(APL_dat.Longitude, APL_dat.Latitude)\n",
    ")\n",
    "\n",
    "gdf_points.set_crs(epsg=4326, inplace=True)\n"
   ],
   "id": "b13906f9-6919-4226-ad4b-d9788b6036c3"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_gdf = gpd.sjoin(gdf_points, aplc_survey_dataframe, how=\"left\", predicate='within')\n"
   ],
   "id": "b979461e-3cec-4b0d-8fe6-2b6a058a46b6"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Longitude        0\n",
      "Latitude         0\n",
      "Date             0\n",
      "Species          0\n",
      "Data.Quality     0\n",
      "Nymph.Density    0\n",
      "Adult.Density    0\n",
      "geometry         0\n",
      "index_right      0\n",
      "polygon_id       0\n",
      "dtype: int64"
     ]
    }
   ],
   "source": [
    "# I wanted to ensure every point has an assoicated polygon_id \n",
    "\n",
    "## which they do\n",
    "\n",
    "na_counts = joined_gdf.isna().sum()\n",
    "\n",
    "print(na_counts)"
   ],
   "id": "4982db06-9b18-401d-99a2-8e4fb78a5a80"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Custom aggregation function to get min, median, and max dates\n",
    "def date_aggregations(series):\n",
    "    series = pd.to_datetime(series, format='%d-%b-%y') # converts to a datatime\n",
    "    return [series.min(), series.median(), series.max()]\n",
    "\n",
    "# aggregation function to count unique values\n",
    "def count_unique_values(series):\n",
    "    return series.value_counts().to_dict()\n",
    "\n",
    "# Group by polygon geometry and aggregate the data\n",
    "aggregated_gdf = joined_gdf.groupby(['Species', 'polygon_id']).agg({\n",
    "    'Date': date_aggregations,\n",
    "    'Longitude': 'median',\n",
    "    'Latitude': 'median',\n",
    "    'Data.Quality': count_unique_values,\n",
    "    'Nymph.Density': count_unique_values,\n",
    "    'Adult.Density': count_unique_values\n",
    "}).reset_index()\n"
   ],
   "id": "154aac4f-b185-43d6-9897-22eec2641829"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "<p>99177 rows × 8 columns</p>\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "aggregated_gdf"
   ],
   "id": "a1aecc29-106a-4d7b-bd83-c06e07c84cc5"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "# Lets count up the total number of observations in the dataframe:\n",
    "\n",
    "# Define the aggregation functions for each column\n",
    "agg_funcs = {\n",
    "    'Data.Quality': 'count',  \n",
    "    'Adult.Density': 'count',    \n",
    "    'Nymph.Density': 'count'    \n",
    "}\n",
    "\n",
    "# Perform groupby operation and aggregate\n",
    "grouped_joined_gdf = joined_gdf.groupby(['Species', 'polygon_id']).agg(agg_funcs).reset_index()\n",
    "\n",
    "# Rename the aggregated columns\n",
    "grouped_joined_gdf.rename(columns={\n",
    "    'Data.Quality': 'Data Quality Total Count',\n",
    "    'Adult.Density': 'Adult Density Total Count',\n",
    "    'Nymph.Density': 'Nymph Density Total Count'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# These three columns should agree with one another....\n",
    "## if any rows dont -- this command filters for them\n",
    "grouped_joined_gdf[\n",
    "    (grouped_joined_gdf['Data Quality Total Count'] != grouped_joined_gdf['Adult Density Total Count']) |\n",
    "    (grouped_joined_gdf['Data Quality Total Count'] != grouped_joined_gdf['Nymph Density Total Count']) |\n",
    "    (grouped_joined_gdf['Adult Density Total Count'] != grouped_joined_gdf['Nymph Density Total Count'])\n",
    "]"
   ],
   "id": "220eaf11-46b0-46e3-a435-af9fcf1fdefc"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Species                      0\n",
      "polygon_id                   0\n",
      "Date                         0\n",
      "Longitude                    0\n",
      "Latitude                     0\n",
      "Data.Quality                 0\n",
      "Nymph.Density                0\n",
      "Adult.Density                0\n",
      "Data Quality Total Count     0\n",
      "Adult Density Total Count    0\n",
      "Nymph Density Total Count    0\n",
      "geometry                     0\n",
      "dtype: int64"
     ]
    }
   ],
   "source": [
    "final_df = pd.merge(aggregated_gdf, grouped_joined_gdf, on=['Species', 'polygon_id'], how='left')\n",
    "final_df = pd.merge(final_df, aplc_survey_dataframe, on='polygon_id', how='left')\n",
    "final_df.head()\n",
    "na_counts = final_df.isna().sum()\n",
    "\n",
    "print(na_counts)"
   ],
   "id": "66a01f23-45b0-41f3-8efa-c2f0244c59fb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The APLC data is complete – lets write to disk"
   ],
   "id": "a1527cc6-91bf-4b76-aa86-314d972120ef"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('data/processed/spatial_modeling/aplc_data_aggregated_to_polygon_grid.csv')"
   ],
   "id": "53baf12a-4255-4c56-997e-b89028f78bac"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
